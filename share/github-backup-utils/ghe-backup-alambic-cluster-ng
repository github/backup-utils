#!/usr/bin/env bash
#/ Usage: ghe-backup-alambic-cluster-ng
#/ Take an online, incremental snapshot of all Alambic Storage data using the
#/ calculated routes method.
#/
#/ Note: This command typically isn't called directly. It's invoked by
#/ ghe-backup when the cluster strategy is used.
set -e

# Bring in the backup configuration
. $( dirname "${BASH_SOURCE[0]}" )/ghe-backup-config

bm_start "$(basename $0)"

# Set up remote host and root backup snapshot directory based on config
host="$GHE_HOSTNAME"
backup_dir="$GHE_SNAPSHOT_DIR/storage"

# Verify rsync is available.
if ! rsync --version 1>/dev/null 2>&1; then
    echo "Error: rsync not found." 1>&2
    exit 1
fi

# Perform a host-check and establish GHE_REMOTE_XXX variables.
ghe_remote_version_required "$host"

# Split host:port into parts
port=$(ssh_port_part "$GHE_HOSTNAME")
host=$(ssh_host_part "$GHE_HOSTNAME")

# Add user / -l option
user="${host%@*}"
[ "$user" = "$host" ] && user="admin"

# storage server hostnames
hostnames=$(ghe-cluster-hostnames "$GHE_HOSTNAME" "storage-server")

tempdir=$(mktemp -d -t backup-utils-restore-XXXXXX)
ghe-ssh "$GHE_HOSTNAME" -- mkdir -p $tempdir
ssh_config_file=$tempdir/ssh_config
ghe-ssh-config "$GHE_HOSTNAME" "$hostnames" > "$ssh_config_file"
opts="$GHE_EXTRA_SSH_OPTS -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -o PasswordAuthentication=no"
routes_list=$tempdir/routes_list

# Make sure root backup dir exists if this is the first run
mkdir -p "$backup_dir"

# Removes the remote sync-in-progress file on exit, re-enabling GC operations
# on the remote instance.
cleanup() {
  # Enable remote maintenance operations
  for hostname in $hostnames; do
    ghe-gc-enable -F $ssh_config_file $hostname:$port
  done

  ghe-ssh "$GHE_HOSTNAME" -- rm -rf $tempdir
  rm -rf $tempdir
}
trap 'cleanup' EXIT INT

# Disable remote maintenance operations
for hostname in $hostnames; do
  ghe-gc-disable -F $ssh_config_file $hostname:$port
done

# If we have a previous increment and it is not empty, avoid transferring existing files via rsync's
# --link-dest support. This also decreases physical space usage considerably.
if [ -d "$GHE_DATA_DIR/current/storage" ] && [ "$(ls -A $GHE_DATA_DIR/current/storage)" ]; then
  link_dest="--link-dest=../../current/storage"
fi

bm_start "$(basename $0) - Generating routes"
echo "github-env ./bin/storage-cluster-backup-routes > $routes_list" | ghe-ssh "$GHE_HOSTNAME" -- /bin/bash
bm_end "$(basename $0) - Generating routes"

bm_start "$(basename $0) - Transferring routes"
ghe-ssh "$GHE_HOSTNAME" -- cat $routes_list > $routes_list
bm_end "$(basename $0) - Transferring routes"

bm_start "$(basename $0) - Processing routes"
cat $routes_list | awk -v tempdir="$tempdir" '{ for(i=2;i<=NF;i++){ print $1 > (tempdir"/"$i".rsync") }}'
bm_end "$(basename $0) - Processing routes"

# rsync all the repositories
bm_start "$(basename $0) - Storage object sync"
for file_list in $tempdir/*.rsync; do
  hostname=$(basename $file_list .rsync)

  object_num=$(cat $file_list | wc -l)
  echo "* Transferring $object_num objects from $hostname"

  ghe-rsync -avr \
  -e "ssh -q $opts -p $port -F $ssh_config_file -l $user" \
  $link_dest "$@" \
  --rsync-path='sudo -u git rsync' \
  --files-from="$file_list" \
  --size-only \
  "$hostname:$GHE_REMOTE_DATA_USER_DIR/storage/" \
  "$backup_dir" 1>&3 &
done

for pid in $(jobs -p); do
  wait $pid
done
bm_end "$(basename $0) - Storage object sync"

bm_end "$(basename $0)"
